{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvDAE.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPq4s5xeJ6rCj8gC99qOAC1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/badadumTss/convDAE/blob/main/ConvDAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports, background\n",
        "As backend for this project we'll use [tensorflow.keras](https://keras.io/), Google's deep learning API. Along with that numpy is very useful to apply all sorts of transformations to the tensors and vector rapresenting our data (e.g. adding noise to an image)."
      ],
      "metadata": {
        "id": "mx4uwlz1V3RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.regularizers import L1\n",
        "from tensorflow.keras import backend as K\n",
        "import tensorflow.keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\") # set the matplotlib backend to save images asyncronously\n",
        "import cv2"
      ],
      "metadata": {
        "id": "qzFzaj5ZpMSM"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The dataset, CIFAR10\n",
        "The choosen dataset for this project is the CIFAR10 dataset. It is a collection of 60000 32x32 colour images grouped in 10 classes, with 6000 images per class (source: [CIFAR10 site](https://www.cs.toronto.edu/~kriz/cifar.html)). This dataset is very suited for the project because the images are not particularly big (32x32 is easily rapresentable with a vector) and has a lot of samples to choose from. It also is one of the default datasets included in the TensorFlow library, so download it is relatively easy."
      ],
      "metadata": {
        "id": "qp4Km31fW9tl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] loading CIFAR10 dataset...\")\n",
        "((trainX, _), (testX, _)) = cifar10.load_data()\n",
        "\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0\n",
        "\n",
        "def add_noise_and_clip_data(data):\n",
        "   noise = np.random.normal(loc=0.0, scale=0.1, size=data.shape)\n",
        "   data = data + noise\n",
        "   data = np.clip(data, 0., 1.)\n",
        "   return data\n",
        "\n",
        "trainXNoisy = add_noise_and_clip_data(trainX)\n",
        "testXNoisy = add_noise_and_clip_data(testX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKxu7yrZXA9k",
        "outputId": "40a6000a-5927-4920-ea52-f85421ebb8d1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading CIFAR10 dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The LinearAutoencoder"
      ],
      "metadata": {
        "id": "6X2UcRmyjMt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearAutoencoder:\n",
        "  @staticmethod\n",
        "  def build(width, height, depth, filters=(32,64), latentDim=16):\n",
        "    inputShape = height * width * depth\n",
        "    channelDim = -1\n",
        "    inputs = Input(shape=(inputShape,))\n",
        "    x = inputs\n",
        "    for f in reversed(filters):\n",
        "      x = Dense(units=f)(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = LeakyReLU()(x)\n",
        "    # encoded space\n",
        "    latent = Dense(units=latentDim,\n",
        "              activation='linear',\n",
        "              activity_regularizer=L1(0.0001))(x)\n",
        "    # encoder\n",
        "    encoder = Model(inputs, latent, name='encoder')\n",
        "    # decoder start\n",
        "    latentInputs = Input(shape=(latentDim,))\n",
        "    y = latentInputs\n",
        "    for f in filters:\n",
        "      y = Dense(units=f)(y)\n",
        "      y = BatchNormalization()(y)\n",
        "      y = LeakyReLU()(y)\n",
        "    \n",
        "    outputs = Dense(units=inputShape, activation='sigmoid')(y)\n",
        "    decoder = Model(latentInputs, outputs, name='decoder')\n",
        "    autoencoder = Model(inputs, outputs, decoder(encoder(inputs)), name='autoencoder')\n",
        "    return (encoder, decoder, autoencoder)"
      ],
      "metadata": {
        "id": "HwPKFBXRjPnb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The ConvAutoencoder\n"
      ],
      "metadata": {
        "id": "g3qM8KhcWe5l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvAutoencoder:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, filters=(32, 64), latentDim=16):\n",
        "\t\t# initialize the input shape to be \"channels last\" along with\n",
        "\t\t# the channels dimension itself\n",
        "\t\t# channels dimension itself\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\t\t# define the input to the encoder\n",
        "\t\tinputs = Input(shape=inputShape)\n",
        "\t\tx = inputs\n",
        "\t\t# loop over the number of filters\n",
        "\t\tfor f in filters:\n",
        "\t\t\t# apply a CONV => RELU => BN operation\n",
        "\t\t\tx = Conv2D(f, (3, 3), strides=2, padding=\"same\")(x)\n",
        "\t\t\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\t\t\tx = BatchNormalization(axis=chanDim)(x)\n",
        "\t\t# flatten the network and then construct our latent vector\n",
        "\t\tvolumeSize = K.int_shape(x)\n",
        "\t\tx = Flatten()(x)\n",
        "\t\tlatent = Dense(latentDim)(x)\n",
        "\t\t# build the encoder model\n",
        "\t\tencoder = Model(inputs, latent, name=\"encoder\")\n",
        "\t\t# start building the decoder model which will accept the\n",
        "\t\t# output of the encoder as its inputs\n",
        "\t\tlatentInputs = Input(shape=(latentDim,))\n",
        "\t\tx = Dense(np.prod(volumeSize[1:]))(latentInputs)\n",
        "\t\tx = Reshape((volumeSize[1], volumeSize[2], volumeSize[3]))(x)\n",
        "\t\t# loop over our number of filters again, but this time in\n",
        "\t\t# reverse order\n",
        "\t\tfor f in filters[::-1]:\n",
        "\t\t\t# apply a CONV_TRANSPOSE => RELU => BN operation\n",
        "\t\t\tx = Conv2DTranspose(f, (3, 3), strides=2,\n",
        "\t\t\t\tpadding=\"same\")(x)\n",
        "\t\t\tx = LeakyReLU(alpha=0.2)(x)\n",
        "\t\t\tx = BatchNormalization(axis=chanDim)(x)\n",
        "\t\t# apply a single CONV_TRANSPOSE layer used to recover the\n",
        "\t\t# original depth of the image\n",
        "\t\tx = Conv2DTranspose(depth, (3, 3), padding=\"same\")(x)\n",
        "\t\toutputs = Activation(\"sigmoid\")(x)\n",
        "\t\t# build the decoder model\n",
        "\t\tdecoder = Model(latentInputs, outputs, name=\"decoder\")\n",
        "\t\t# our autoencoder is the encoder + decoder\n",
        "\t\tautoencoder = Model(inputs, decoder(encoder(inputs)),\n",
        "\t\t\tname=\"autoencoder\")\n",
        "\t\t# return a 3-tuple of the encoder, decoder, and autoencoder\n",
        "\t\treturn (encoder, decoder, autoencoder)"
      ],
      "metadata": {
        "id": "R4F0w3_gVJgV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The test function"
      ],
      "metadata": {
        "id": "SJN6BPAAzHNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to use wandb we also have to login, the given key is my personal test key, feel free to use it for now"
      ],
      "metadata": {
        "id": "YpQZJsNo0I3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "vscode": {
          "languageId": "python"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO9pcIvWo-8y",
        "outputId": "445ced8d-c4b0-454d-ee83-d24546457107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbadadumtss\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Configure wandb\n",
        "In this section we'll configure sweep, one of wandb products that allows for optimal hyperparameter search."
      ],
      "metadata": {
        "id": "mXM-8Uhn10ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_config = {\n",
        "    'method': 'random',\n",
        "    'metric': {\n",
        "        'name': 'loss',\n",
        "        'goal': 'minimize'\n",
        "    }\n",
        "}\n",
        "\n",
        "params = {\n",
        "    'model': {\n",
        "        'values': ['linear', 'convolutional']\n",
        "    },\n",
        "    'epochs': {\n",
        "        'value': 5\n",
        "    },\n",
        "    'batch_size': {\n",
        "        'value': 32\n",
        "    },\n",
        "    'latent_dim': {\n",
        "        'values': [128, 32, 16]\n",
        "    },\n",
        "    'filters': {\n",
        "        'values': [(32, 64), (32, 64, 128)]\n",
        "    },\n",
        "    'learning_rate': {\n",
        "        'values': [1e-4, 1e-3, 0.01]\n",
        "    }\n",
        "}\n",
        "\n",
        "sweep_config['parameters'] = params\n"
      ],
      "metadata": {
        "id": "FSfs4uwO13dJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the sweep"
      ],
      "metadata": {
        "id": "J5UrAcJS3bUI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sweep_id = wandb.sweep(sweep_config, project=\"convDAE\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWs9TYCK3evF",
        "outputId": "6836fdea-84f5-4519-bc33-a4345bab02df"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 0vxf9yf9\n",
            "Sweep URL: https://wandb.ai/badadumtss/convDAE/sweeps/0vxf9yf9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the training\n"
      ],
      "metadata": {
        "id": "1sM-x-fE3piP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(config):\n",
        "  if config.model == 'linear':\n",
        "    return LinearAutoencoder.build(32, 32, 3, filters=config.filters, latentDim=config.latent_dim)\n",
        "  if config.model == 'convolutional':\n",
        "    return ConvAutoencoder.build(32, 32, 3, filters=config.filters, latentDim=config.latent_dim)"
      ],
      "metadata": {
        "id": "5G8cWHETpljn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(config=None):\n",
        "  with wandb.init(config=config):\n",
        "    config = wandb.config\n",
        "    optimizer = Adam(learning_rate = config.learning_rate)\n",
        "    # construct our convolutional autoencoder\n",
        "    print(\"[INFO] building autoencoder...\")\n",
        "    (encoder, decoder, autoencoder) = build_model(config)\n",
        "\n",
        "    global trainXNoisy\n",
        "    global trainX\n",
        "    if config.model == 'linear':\n",
        "      trainXNoisy = trainXNoisy.reshape(60000, 3072)\n",
        "      trainX = trainX.reshape(60000, 3072)\n",
        "    \n",
        "    autoencoder.compile(loss=\"mse\", optimizer=optimizer, metrics=['accuracy'])\n",
        "    # train the convolutional autoencoder\n",
        "    H = autoencoder.fit(\n",
        "\t    trainXNoisy, trainX,\n",
        "\t    validation_data=(testXNoisy, testX),\n",
        "\t    epochs=config.epochs,\n",
        "\t    batch_size=config.batch_size\n",
        "    )\n",
        "    \n",
        "    wandb.log({'epochs': config.epochs,\n",
        "                'loss': np.mean(H.history['loss']),\n",
        "                'val_loss': np.mean(H.history['val_loss'])})\n",
        "    del encoder\n",
        "    del decoder\n",
        "    del autoencoder\n",
        "    "
      ],
      "metadata": {
        "id": "EMovZgHi3tYV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the sweeper"
      ],
      "metadata": {
        "id": "2Otan6KO614E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.agent(sweep_id, train, count=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "6wnmThZ061MO",
        "outputId": "39cd6758-4a36-43e8-b40a-02d8d05ff109"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ctgbmdxp with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tfilters: [32, 64]\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlatent_dim: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tmodel: convolutional\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.21"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220714_075923-ctgbmdxp</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/badadumtss/convDAE/runs/ctgbmdxp\" target=\"_blank\">laced-sweep-1</a></strong> to <a href=\"https://wandb.ai/badadumtss/convDAE\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/badadumtss/convDAE/sweeps/0vxf9yf9\" target=\"_blank\">https://wandb.ai/badadumtss/convDAE/sweeps/0vxf9yf9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] building autoencoder...\n",
            "Epoch 1/5\n",
            "1233/1563 [======================>.......] - ETA: 34s - loss: 0.0205 - accuracy: 0.5564"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
          ]
        }
      ]
    }
  ]
}